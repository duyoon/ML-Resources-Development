{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 06 머신러닝, 딥러닝 기초 이론\n",
    "\n",
    "## 7. 심층 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daeung\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_val = mnist.validation.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_val = mnist.validation.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (5000, 784) (10000, 784)\n",
      "(55000,) (5000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape) \n",
    "print(y_train.shape, y_val.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[22000].reshape(28, 28), \n",
    "           cmap = matplotlib.cm.binary)\n",
    "plt.title(\"Label = {}\".format(y_train[22000]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 2개의 은닉층과 시그모이드 활성함수를 이용한 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.53125 Val accuracy: 0.7074\n",
      "1 Train accuracy: 0.65625 Val accuracy: 0.795\n",
      "2 Train accuracy: 0.8125 Val accuracy: 0.8288\n",
      "3 Train accuracy: 0.84375 Val accuracy: 0.8476\n",
      "4 Train accuracy: 0.875 Val accuracy: 0.864\n",
      "5 Train accuracy: 0.96875 Val accuracy: 0.875\n",
      "6 Train accuracy: 0.84375 Val accuracy: 0.88\n",
      "7 Train accuracy: 0.90625 Val accuracy: 0.8876\n",
      "8 Train accuracy: 0.875 Val accuracy: 0.89\n",
      "9 Train accuracy: 0.875 Val accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform((n_inputs, n_hidden1),-1.0, 1.0, seed=0), name=\"weights1\")\n",
    "b1 = tf.Variable(tf.zeros([n_hidden1]), name=\"bias1\")\n",
    "Z1 = tf.add(tf.matmul(X, W1), b1, name=\"z1\")\n",
    "sig1= tf.nn.sigmoid(Z1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform((n_hidden1, n_hidden2),-1.0, 1.0, seed=0), name=\"weights2\")\n",
    "b2 = tf.Variable(tf.zeros([n_hidden2]), name=\"bias2\")\n",
    "Z2 = tf.add(tf.matmul(sig1, W2), b2, name=\"z2\")\n",
    "sig2= tf.nn.sigmoid(Z2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform((n_hidden2, n_outputs),-1.0, 1.0, seed=0), name=\"weights3\")\n",
    "b3 = tf.Variable(tf.zeros([n_outputs]), name=\"bias2\")\n",
    "logits = tf.add(tf.matmul(sig2, W3), b3, name=\"logit\")\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 활성함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9375 Val accuracy: 0.8868\n",
      "1 Train accuracy: 1.0 Val accuracy: 0.9058\n",
      "2 Train accuracy: 1.0 Val accuracy: 0.9118\n",
      "3 Train accuracy: 0.96875 Val accuracy: 0.911\n",
      "4 Train accuracy: 1.0 Val accuracy: 0.9268\n",
      "5 Train accuracy: 1.0 Val accuracy: 0.9264\n",
      "6 Train accuracy: 0.90625 Val accuracy: 0.9248\n",
      "7 Train accuracy: 0.875 Val accuracy: 0.924\n",
      "8 Train accuracy: 0.96875 Val accuracy: 0.934\n",
      "9 Train accuracy: 0.96875 Val accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform((n_inputs, n_hidden1),-1.0, 1.0, seed=0), name=\"weights1\")\n",
    "b1 = tf.Variable(tf.zeros([n_hidden1]), name=\"bias1\")\n",
    "Z1 = tf.add(tf.matmul(X, W1), b1, name=\"z1\")\n",
    "leaky_relu1= tf.nn.leaky_relu(Z1)                                #변경된 부분\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform((n_hidden1, n_hidden2),-1.0, 1.0, seed=0), name=\"weights2\")\n",
    "b2 = tf.Variable(tf.zeros([n_hidden2]), name=\"bias2\")\n",
    "Z2 = tf.add(tf.matmul(leaky_relu1, W2), b2, name=\"z2\")                 #변경된 부분\n",
    "leaky_relu2= tf.nn.leaky_relu(Z2)                                #변경된 부분\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform((n_hidden2, n_outputs),-1.0, 1.0, seed=0), name=\"weights3\")\n",
    "b3 = tf.Variable(tf.zeros([n_outputs]), name=\"bias2\")\n",
    "logits = tf.add(tf.matmul(leaky_relu2, W3), b3, name=\"logit\")    #변경된 부분\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Xavier/He 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.90625 Val accuracy: 0.9114\n",
      "1 Train accuracy: 0.90625 Val accuracy: 0.9284\n",
      "2 Train accuracy: 0.9375 Val accuracy: 0.9386\n",
      "3 Train accuracy: 1.0 Val accuracy: 0.9442\n",
      "4 Train accuracy: 0.96875 Val accuracy: 0.9514\n",
      "5 Train accuracy: 0.96875 Val accuracy: 0.9538\n",
      "6 Train accuracy: 0.96875 Val accuracy: 0.9584\n",
      "7 Train accuracy: 1.0 Val accuracy: 0.9612\n",
      "8 Train accuracy: 1.0 Val accuracy: 0.9648\n",
      "9 Train accuracy: 0.96875 Val accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "stddev = np.sqrt(2 / n_inputs)\n",
    "W1 = tf.Variable(tf.truncated_normal((n_inputs, n_hidden1), stddev=stddev, seed=0), name=\"weights1\")\n",
    "b1 = tf.Variable(tf.zeros([n_hidden1]), name=\"bias1\")\n",
    "Z1 = tf.add(tf.matmul(X, W1), b1, name=\"z1\")\n",
    "relu1= tf.nn.leaky_relu(Z1)\n",
    "\n",
    "stddev = np.sqrt(2 / n_hidden1)\n",
    "W2 = tf.Variable(tf.truncated_normal((n_hidden1, n_hidden2), stddev=stddev, seed=0), name=\"weights2\")\n",
    "b2 = tf.Variable(tf.zeros([n_hidden2]), name=\"bias2\")\n",
    "Z2 = tf.add(tf.matmul(relu1, W2), b2, name=\"z2\")\n",
    "relu2= tf.nn.leaky_relu(Z2)\n",
    "\n",
    "stddev = np.sqrt(2 / n_hidden2)\n",
    "W3 = tf.Variable(tf.truncated_normal((n_hidden2, n_outputs), stddev=stddev, seed=0), name=\"weights3\")\n",
    "b3 = tf.Variable(tf.zeros([n_outputs]), name=\"bias2\")\n",
    "logits = tf.add(tf.matmul(relu2, W3), b3, name=\"logit\")\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.layers.dense` 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9375 Val accuracy: 0.9148\n",
      "1 Train accuracy: 1.0 Val accuracy: 0.9294\n",
      "2 Train accuracy: 0.96875 Val accuracy: 0.9398\n",
      "3 Train accuracy: 1.0 Val accuracy: 0.9468\n",
      "4 Train accuracy: 1.0 Val accuracy: 0.9508\n",
      "5 Train accuracy: 0.96875 Val accuracy: 0.955\n",
      "6 Train accuracy: 0.9375 Val accuracy: 0.9592\n",
      "7 Train accuracy: 0.96875 Val accuracy: 0.9634\n",
      "8 Train accuracy: 0.96875 Val accuracy: 0.9658\n",
      "9 Train accuracy: 0.9375 Val accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()   \n",
    "\n",
    "hidden1= tf.layers.dense(X, n_hidden1, \n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                         activation=tf.nn.leaky_relu, \n",
    "                         name=\"hidden1\")\n",
    "\n",
    "hidden2= tf.layers.dense(hidden1, n_hidden2, \n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                         activation=tf.nn.leaky_relu,\n",
    "                         name=\"hidden2\", )\n",
    "logits =tf.layers.dense(hidden2, n_outputs, \n",
    "                        kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                        name=\"outputs\") \n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 배치 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.90625 Val accuracy: 0.9282\n",
      "1 Train accuracy: 0.9375 Val accuracy: 0.9462\n",
      "2 Train accuracy: 0.96875 Val accuracy: 0.957\n",
      "3 Train accuracy: 1.0 Val accuracy: 0.9652\n",
      "4 Train accuracy: 1.0 Val accuracy: 0.9676\n",
      "5 Train accuracy: 1.0 Val accuracy: 0.9688\n",
      "6 Train accuracy: 0.96875 Val accuracy: 0.9724\n",
      "7 Train accuracy: 1.0 Val accuracy: 0.9744\n",
      "8 Train accuracy: 1.0 Val accuracy: 0.9742\n",
      "9 Train accuracy: 1.0 Val accuracy: 0.9752\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.9762\n",
      "11 Train accuracy: 1.0 Val accuracy: 0.9772\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.9784\n",
      "13 Train accuracy: 1.0 Val accuracy: 0.9776\n",
      "14 Train accuracy: 0.96875 Val accuracy: 0.9766\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.9794\n",
      "16 Train accuracy: 1.0 Val accuracy: 0.9782\n",
      "17 Train accuracy: 1.0 Val accuracy: 0.978\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.9776\n",
      "19 Train accuracy: 1.0 Val accuracy: 0.9804\n",
      "20 Train accuracy: 1.0 Val accuracy: 0.981\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.9798\n",
      "22 Train accuracy: 1.0 Val accuracy: 0.9786\n",
      "23 Train accuracy: 1.0 Val accuracy: 0.982\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.98\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.9818\n",
      "26 Train accuracy: 1.0 Val accuracy: 0.9818\n",
      "27 Train accuracy: 1.0 Val accuracy: 0.9804\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.9828\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()   \n",
    "\n",
    "hidden1= tf.layers.dense(X, n_hidden1, kernel_initializer=he_init, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, kernel_initializer=he_init, name=\"hidden2\")\n",
    "bn2 =  tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn =tf.layers.dense(bn2_act, n_outputs, kernel_initializer=he_init, name=\"outputs\") \n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training, momentum=0.9)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "moving_average_update_op = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "acc_GD = []\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, moving_average_update_op], \n",
    "                     feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        acc_GD.append(acc_val)\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.90625 Val accuracy: 0.8868\n",
      "1 Train accuracy: 0.9375 Val accuracy: 0.908\n",
      "2 Train accuracy: 0.90625 Val accuracy: 0.916\n",
      "3 Train accuracy: 0.8125 Val accuracy: 0.9194\n",
      "4 Train accuracy: 0.9375 Val accuracy: 0.9258\n",
      "5 Train accuracy: 0.875 Val accuracy: 0.9284\n",
      "6 Train accuracy: 0.96875 Val accuracy: 0.9312\n",
      "7 Train accuracy: 0.9375 Val accuracy: 0.9332\n",
      "8 Train accuracy: 0.9375 Val accuracy: 0.937\n",
      "9 Train accuracy: 0.90625 Val accuracy: 0.9378\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "dropout_rate = 0.5\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()   \n",
    "\n",
    "hidden1= tf.layers.dense(X, n_hidden1, kernel_initializer=he_init, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden1_drop = tf.layers.dropout(bn1_act, dropout_rate, training=training)\n",
    "\n",
    "\n",
    "hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, kernel_initializer=he_init, name=\"hidden2\")\n",
    "bn2 =  tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "hidden2_drop = tf.layers.dropout(bn2_act, dropout_rate, training=training)\n",
    "\n",
    "logits_before_bn =tf.layers.dense(hidden2_drop, n_outputs, kernel_initializer=he_init, name=\"outputs\") \n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training, momentum=0.9)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "moving_average_update_op = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "acc_drop = []\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, moving_average_update_op], \n",
    "                     feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        acc_drop.append(acc_val)\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.96875 Val accuracy: 0.9662\n",
      "1 Train accuracy: 1.0 Val accuracy: 0.9738\n",
      "2 Train accuracy: 1.0 Val accuracy: 0.9772\n",
      "3 Train accuracy: 0.9375 Val accuracy: 0.979\n",
      "4 Train accuracy: 1.0 Val accuracy: 0.9786\n",
      "5 Train accuracy: 0.96875 Val accuracy: 0.981\n",
      "6 Train accuracy: 1.0 Val accuracy: 0.9812\n",
      "7 Train accuracy: 1.0 Val accuracy: 0.9824\n",
      "8 Train accuracy: 1.0 Val accuracy: 0.9814\n",
      "9 Train accuracy: 1.0 Val accuracy: 0.9842\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.9826\n",
      "11 Train accuracy: 1.0 Val accuracy: 0.9828\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.9812\n",
      "13 Train accuracy: 1.0 Val accuracy: 0.9836\n",
      "14 Train accuracy: 1.0 Val accuracy: 0.9838\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.984\n",
      "16 Train accuracy: 1.0 Val accuracy: 0.9846\n",
      "17 Train accuracy: 1.0 Val accuracy: 0.9838\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.9846\n",
      "19 Train accuracy: 1.0 Val accuracy: 0.9844\n",
      "20 Train accuracy: 1.0 Val accuracy: 0.9846\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.9838\n",
      "22 Train accuracy: 1.0 Val accuracy: 0.9836\n",
      "23 Train accuracy: 1.0 Val accuracy: 0.9834\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.9812\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.9852\n",
      "26 Train accuracy: 1.0 Val accuracy: 0.9852\n",
      "27 Train accuracy: 1.0 Val accuracy: 0.9866\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.985\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()   \n",
    "\n",
    "hidden1= tf.layers.dense(X, n_hidden1, kernel_initializer=he_init, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, kernel_initializer=he_init, name=\"hidden2\")\n",
    "bn2 =  tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn =tf.layers.dense(bn2_act, n_outputs, kernel_initializer=he_init, name=\"outputs\") \n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training, momentum=0.9)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "moving_average_update_op = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "acc_adam = []\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, moving_average_update_op], \n",
    "                     feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        acc_adam.append(acc_val)\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'validation accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_GD, 'k-')\n",
    "plt.plot(acc_adam , 'k--')\n",
    "plt.legend(['GradientDescent', 'Adam'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
